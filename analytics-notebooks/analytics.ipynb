{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date: 2020/02\n",
    "\n",
    "#### SUMMARY:\n",
    "\n",
    "- This notebook represents the project quality analysis of the date exposed right above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM: SiGeD\n",
    "\n",
    "##### Semester: 2020/02\n",
    "##### Professor: Hilmer Neri\n",
    "\n",
    "##### Members:\n",
    "\n",
    "- Vitor Leal\n",
    "- Gabriel Carvalho\n",
    "- Ezequiel de Oliveira\n",
    "- Gabriela Guedes\n",
    "- Davi Marinho da Silva Campos\n",
    "- João Pedro Alves da Silva Chaves\n",
    "- Thiago França Vale Oliveira\n",
    "- Lucas da Cunha Andrade\n",
    "- Dafne Moretti Moreira\n",
    "- Victor Yukio Cavalcanti Miki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3fffc627a7ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Deal with data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Deal with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# Deal with API request\n",
    "import urllib3\n",
    "from urllib3 import request\n",
    "\n",
    "# Deal with visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: pandas in /Users/gabibguedes/Library/Python/2.7/lib/python/site-packages (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /Users/gabibguedes/Library/Python/2.7/lib/python/site-packages (from pandas) (1.16.6)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas) (2013.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /Users/gabibguedes/Library/Python/2.7/lib/python/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina'\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('darkgrid',\n",
    "              {'xtick.bottom' : True,\n",
    "               'ytick.left': True,\n",
    "               'grid.linestyle':'--',\n",
    "               'font.monospace': ['Computer Modern Typewriter'],\n",
    "               'axes.edgecolor' : 'white'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SonarCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path to the folder with all your jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = glob('data/release_jsons/*.json') # add the path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path):\n",
    "    \n",
    "    with open(json_path) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        \n",
    "    return json_obj\n",
    "\n",
    "def create_base_component_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        base_component = read_json(i)\n",
    "\n",
    "        base_component_data = base_component['baseComponent']['measures']\n",
    "\n",
    "        base_component_df = pd.DataFrame(base_component_data)\n",
    "\n",
    "        base_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(base_component_df, ignore_index=True)\n",
    "        \n",
    "    aux_df = df['filename'].str.split(r\"SiGeD-(.*?)-date_(.*?).json\", expand=True)\n",
    "    \n",
    "    df['repository'] = aux_df[1]\n",
    "    \n",
    "    df['version'] = aux_df[2]\n",
    "    \n",
    "    df = df.sort_values(by=['repository', 'version'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create base component dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_component_df = create_base_component_df(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_component_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = ['files',\n",
    "               'functions',\n",
    "               'complexity',\n",
    "               'comment_lines_density',\n",
    "               'duplicated_lines_density',\n",
    "               'coverage',\n",
    "               'ncloc',\n",
    "               'security_rating',\n",
    "               'tests',\n",
    "               'test_success_density',\n",
    "               'test_execution_time',\n",
    "               'reliability_rating']\n",
    "\n",
    "len(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_per_file(json):\n",
    "    \n",
    "    file_json = []\n",
    "    \n",
    "    for component in json['components']:\n",
    "        if component['qualifier'] == 'FIL':\n",
    "            file_json.append(component)\n",
    "            \n",
    "    return file_json\n",
    "\n",
    "def generate_file_dataframe_per_release(metric_list, json, language_extension):\n",
    "    \n",
    "    df_columns = metric_list\n",
    "    df = pd.DataFrame(columns = df_columns)\n",
    "    \n",
    "    for file in json:\n",
    "        try:\n",
    "            if file['language'] == language_extension:\n",
    "                for measure in file['measures']:\n",
    "                    df.at[file['path'], measure['metric']] = measure['value']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    df.reset_index(inplace = True)\n",
    "    df = df.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_file_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        file_component = read_json(i)\n",
    "        \n",
    "        file_component_data = metric_per_file(file_component)\n",
    "\n",
    "        file_component_df = generate_file_dataframe_per_release(metric_list, file_component_data, language_extension = 'js')\n",
    "\n",
    "        file_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(file_component_df, ignore_index=True)\n",
    "        \n",
    "    # replace TeamName by yours.    \n",
    "    aux_df = df['filename'].str.split(r\"TeamName-(.*?)-date_(.*?).json\", expand=True)\n",
    "    \n",
    "    df['repository'] = aux_df[1]\n",
    "    \n",
    "    df['version'] = aux_df[2]\n",
    "    \n",
    "    df = df.sort_values(by=['repository', 'version'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_component_df = create_file_df(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_component_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_component_df.to_excel('data/data.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe per repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "repo1_df = file_component_df[file_component_df['repository'] == 'repo1']\n",
    "repo2_df = file_component_df[file_component_df['repository'] == 'repo2']\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1(df):\n",
    "    \n",
    "    density_non_complex_files = len(df[(df['complexity'].astype(float)/df['functions'].astype(float)) < 10])/len(df)\n",
    "    \n",
    "    return density_non_complex_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2(df):\n",
    "    \n",
    "    density_comment_files = len(df[(df['comment_lines_density'].astype(float) > 10) & (df['comment_lines_density'].astype(float) < 30)])/len(df)\n",
    "    \n",
    "    return density_comment_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DUPLICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m3(df):\n",
    "    \n",
    "    duplication = len(df[(df['duplicated_lines_density'].astype(float) < 5)])/len(df)\n",
    "    \n",
    "    return duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate m1, m2 and m3 for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_df(df):\n",
    "    \n",
    "    version_vec = df['version'].unique()\n",
    "    \n",
    "    m1_list = []\n",
    "    m2_list = []\n",
    "    m3_list = []\n",
    "    repository_list = []\n",
    "    version_list = []\n",
    "    \n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for version in version_vec:\n",
    "\n",
    "        version_df = df[df['version'] == version]\n",
    "\n",
    "        m1_list.append(m1(version_df))\n",
    "        m2_list.append(m2(version_df))\n",
    "        m3_list.append(m3(version_df))\n",
    "        repository_list.append(version_df['repository'].iloc[0])\n",
    "        version_list.append(version)\n",
    "        \n",
    "    metrics_df = pd.DataFrame({'m1': m1_list,\n",
    "                               'm2': m2_list,\n",
    "                               'm3': m3_list,\n",
    "                               'repository': repository_list, \n",
    "                               'version': version_list})\n",
    "        \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo1_metrics = create_metrics_df(repo1_df)\n",
    "repo2_metrics = create_metrics_df(repo2_df)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "- You must do this for each of your repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(repo1['m1'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(repo1['m2'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(repo1['m3'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(repo1['m1'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo1['m2'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo1['m3'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub characteristic aggregation\n",
    "\n",
    "- You must do this for each of your repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psc1 = 1\n",
    "pm1 = 0.33\n",
    "pm2 = 0.33\n",
    "pm3 = 0.33\n",
    "\n",
    "repo1['asc1'] = ((repo1['m1']*pm1)+(repo1['m2']*pm2)+(repo1['m3']*pm3))*psc1\n",
    "repo2['asc1'] = ((repo2['m1']*pm1)+(repo2['m2']*pm2)+(repo2['m3']*pm3))*psc1\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(repo1['asc1'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(repo2['asc1'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "\n",
    "plt.plot(repo1['asc1'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo2['asc1'], linewidth=3, marker='o', markersize=5)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.concat([repo1_metrics, repo2_metrics, ...], ignore_index=True)\n",
    "\n",
    "metrics_df['ac1'] = metrics_df['asc1'] * 1\n",
    "metrics_df['total'] = metrics_df['asc1'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_excel('data/metrics_df.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
